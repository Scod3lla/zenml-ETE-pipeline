{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch model of a specified Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.post_execution import get_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = get_pipelines()\n",
    "\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.post_execution import get_pipeline\n",
    "\n",
    "# This way you can get a pipeline by name\n",
    "pipeline_x = get_pipeline(pipeline=\"pytorch_experiment_tracking_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.post_execution import get_pipeline\n",
    "\n",
    "pipeline = get_pipeline(pipeline=\"pytorch_experiment_tracking_pipeline\")\n",
    "last_run = pipeline.runs[0]\n",
    "last_step = last_run.steps[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(\n",
      "  (linear): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = last_step.outputs[\"trained_model\"].read()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000575309\n"
     ]
    }
   ],
   "source": [
    "test_acc = last_step.outputs[\"test_acc\"].read()\n",
    "print(f'{test_acc:.10f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fetched model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "data = pd.read_csv('./data/data.txt', header=None, delim_whitespace=True)\n",
    "features = pd.read_csv('./data/Features.txt', header=None)\n",
    "columns = features.values.squeeze()\n",
    "dictionary_columns = {x.split(' - ')[0]: x for x in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.data = pd.read_csv(csv_path, header=None, delim_whitespace=True)\n",
    "        x = self.data.iloc[:,:-2].values\n",
    "        y = self.data.iloc[:,-1].values\n",
    "\n",
    "        x = torch.tensor(x, dtype =torch.float32)\n",
    "        self.x_train = torch.nn.functional.normalize(x, p=1.0, dim=1, eps=1e-12, out=None)\n",
    "\n",
    "        self.y_train = torch.tensor(y, dtype =torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    def __getitem__ (self,idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa= CustomDatasetFromCSV('./data/data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_size = int(0.8 * len(aaa))\n",
    "test_size = len(aaa) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(aaa, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for id in range(len(test_dataset)):\n",
    "        X, y = test_dataset[id]\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        p = pred.item()\n",
    "        gt = y.item()\n",
    "        print(f'prediction: {p:.3f}, gt: {gt:.3f}, difference: {p - gt:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
